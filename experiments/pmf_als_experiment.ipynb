{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PMF–ALS Experiment: Testing Subspace Invariance Theory\n",
    "\n",
    "## Core Theoretical Claim\n",
    "\n",
    "**When ALS is initialized in the subspace spanned by specific singular vectors of Y, it will:**\n",
    "1. **Stay in that subspace** (subspace invariance)\n",
    "2. **Converge to the stationary point** obtained by soft-thresholding the corresponding singular values\n",
    "\n",
    "## Mathematical Setup\n",
    "\n",
    "- **MAP Objective:** $L(U,V) = \\frac{1}{2}\\|Y - UV^\\top\\|_F^2 + \\frac{\\lambda}{2}(\\|U\\|_F^2 + \\|V\\|_F^2)$\n",
    "- **Global Minimizer:** $U^* = F_R \\text{diag}\\big(\\sqrt{(\\sigma_i - \\lambda)_+}\\big)$, $V^* = G_R \\text{diag}\\big(\\sqrt{(\\sigma_i - \\lambda)_+}\\big)$\n",
    "- **Soft-thresholding:** $(x)_+ = \\max(x,0)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup: Parameters and Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPERIMENT SETUP ===\n",
      "Matrix size: 10 × 8\n",
      "Singular values: [10, 8, 4, 1]\n",
      "Regularization λ = 2\n",
      "Latent rank R = 3\n",
      "Top subspace indices: [0, 1, 2]\n",
      "Alt subspace indices: [1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as npl\n",
    "\n",
    "# Fixed seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# === EXPERIMENT PARAMETERS ===\n",
    "# Matrix dimensions (smaller for clarity)\n",
    "m, n = 10, 8\n",
    "true_rank = 4\n",
    "\n",
    "# Clean integer singular values (hardcoded for interpretability)\n",
    "# add some noise to singular values\n",
    "singular_values = [10, 8, 4, 1] \n",
    "\n",
    "# ALS parameters\n",
    "R = 3                  # Latent factorization rank\n",
    "lambda_reg = 2         # Regularization parameter\n",
    "\n",
    "# Subspace selection\n",
    "top_indices = [0, 1, 2]        # Top 3 singular vectors\n",
    "alt_indices = [1, 2, 3]        # Alternative 3 (overlapping set)\n",
    "\n",
    "print(\"=== EXPERIMENT SETUP ===\")\n",
    "print(f\"Matrix size: {m} × {n}\")\n",
    "print(f\"Singular values: {singular_values}\")\n",
    "print(f\"Regularization λ = {lambda_reg}\")\n",
    "print(f\"Latent rank R = {R}\")\n",
    "print(f\"Top subspace indices: {top_indices}\")\n",
    "print(f\"Alt subspace indices: {alt_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DATA GENERATION VERIFICATION ===\n",
      "Y shape: (10, 8)\n",
      "Recovered singular values: [10.  8.  4.  1.]\n",
      "Expected singular values:  [10, 8, 4, 1]\n",
      "Match: True\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic matrix with known structure\n",
    "# Y = U_true * S_true * V_true^T\n",
    "U_true, _ = np.linalg.qr(np.random.randn(m, true_rank))\n",
    "V_true, _ = np.linalg.qr(np.random.randn(n, true_rank))\n",
    "Y = U_true @ np.diag(singular_values) @ V_true.T\n",
    "\n",
    "# Compute SVD of Y (should recover our structure)\n",
    "U_svd, s_svd, Vt_svd = npl.svd(Y, full_matrices=False)\n",
    "V_svd = Vt_svd.T\n",
    "\n",
    "print(\"\\n=== DATA GENERATION VERIFICATION ===\")\n",
    "print(f\"Y shape: {Y.shape}\")\n",
    "print(f\"Recovered singular values: {s_svd[:4].round(6)}\")\n",
    "print(f\"Expected singular values:  {singular_values}\")\n",
    "print(f\"Match: {np.allclose(s_svd[:4], singular_values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Theory: Expected Solutions via Soft-Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SOFT-THRESHOLDING ANALYSIS ===\n",
      "Regularization λ = 2\n",
      "\n",
      "Top subspace (indices [0, 1, 2]):\n",
      "  Singular values: [10.  8.  4.]\n",
      "  After thresholding: [8. 6. 2.]\n",
      "  Target scales: [2.828 2.449 1.414]\n",
      "\n",
      "Alt subspace (indices [1, 2, 3]):\n",
      "  Singular values: [8. 4. 1.]\n",
      "  After thresholding: [6. 2. 0.]\n",
      "  Target scales: [2.449 1.414 0.   ]\n"
     ]
    }
   ],
   "source": [
    "def soft_threshold(sigma, lam):\n",
    "    \"\"\"Apply soft-thresholding: max(sigma - lambda, 0)\"\"\"\n",
    "    return np.maximum(sigma - lam, 0.0)\n",
    "\n",
    "def compute_map_solution(U_svd_subset, V_svd_subset, sigma_subset, lam):\n",
    "    \"\"\"Compute MAP solution U*, V* for given subspace\"\"\"\n",
    "    # Apply soft-thresholding to get target scalings\n",
    "    target_scales = np.sqrt(soft_threshold(sigma_subset, lam))\n",
    "    \n",
    "    # Form MAP solution matrices\n",
    "    U_target = U_svd_subset @ np.diag(target_scales)\n",
    "    V_target = V_svd_subset @ np.diag(target_scales)\n",
    "    \n",
    "    return U_target, V_target, target_scales\n",
    "\n",
    "# Extract subspace components\n",
    "U_svd_top = U_svd[:, top_indices]\n",
    "V_svd_top = V_svd[:, top_indices] \n",
    "sigma_top = s_svd[top_indices]\n",
    "\n",
    "U_svd_alt = U_svd[:, alt_indices]\n",
    "V_svd_alt = V_svd[:, alt_indices]\n",
    "sigma_alt = s_svd[alt_indices]\n",
    "\n",
    "# Compute theoretical MAP solutions\n",
    "U_target_top, V_target_top, scales_top = compute_map_solution(U_svd_top, V_svd_top, sigma_top, lambda_reg)\n",
    "U_target_alt, V_target_alt, scales_alt = compute_map_solution(U_svd_alt, V_svd_alt, sigma_alt, lambda_reg)\n",
    "\n",
    "print(\"=== SOFT-THRESHOLDING ANALYSIS ===\")\n",
    "print(f\"Regularization λ = {lambda_reg}\")\n",
    "print()\n",
    "print(f\"Top subspace (indices {top_indices}):\")\n",
    "print(f\"  Singular values: {sigma_top.round(2)}\")\n",
    "print(f\"  After thresholding: {soft_threshold(sigma_top, lambda_reg).round(2)}\")\n",
    "print(f\"  Target scales: {scales_top.round(3)}\")\n",
    "print()\n",
    "print(f\"Alt subspace (indices {alt_indices}):\")\n",
    "print(f\"  Singular values: {sigma_alt.round(2)}\")\n",
    "print(f\"  After thresholding: {soft_threshold(sigma_alt, lambda_reg).round(2)}\")\n",
    "print(f\"  Target scales: {scales_alt.round(3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize: Set ALS Starting Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INITIALIZATION ===\n",
      "Top subspace - Initial U scales: [1.66 1.24 1.28]\n",
      "Top subspace - Initial V scales: [1.14 0.54 0.66]\n",
      "Alt subspace - Initial U scales: [0.55 1.45 0.97]\n",
      "Alt subspace - Initial V scales: [1.26 1.86 0.87]\n",
      "\n",
      "Key insight: ALS should adjust these random scalings to the optimal target scales!\n"
     ]
    }
   ],
   "source": [
    "def initialize_in_subspace(U_svd_subset, V_svd_subset, scale_range=(0.5, 2.0)):\n",
    "    \"\"\"Initialize U0, V0 in given subspace with random scalings\"\"\"\n",
    "    R = U_svd_subset.shape[1]\n",
    "    \n",
    "    # Random scaling factors\n",
    "    scales_U = np.random.uniform(scale_range[0], scale_range[1], R)\n",
    "    scales_V = np.random.uniform(scale_range[0], scale_range[1], R)\n",
    "    \n",
    "    # Initialize in subspace with random scalings\n",
    "    U0 = U_svd_subset @ np.diag(scales_U)\n",
    "    V0 = V_svd_subset @ np.diag(scales_V)\n",
    "    \n",
    "    return U0, V0, scales_U, scales_V\n",
    "\n",
    "# Initialize ALS starting points in each subspace\n",
    "U0_top, V0_top, init_scales_U_top, init_scales_V_top = initialize_in_subspace(U_svd_top, V_svd_top)\n",
    "U0_alt, V0_alt, init_scales_U_alt, init_scales_V_alt = initialize_in_subspace(U_svd_alt, V_svd_alt)\n",
    "\n",
    "print(\"=== INITIALIZATION ===\")\n",
    "print(f\"Top subspace - Initial U scales: {init_scales_U_top.round(2)}\")\n",
    "print(f\"Top subspace - Initial V scales: {init_scales_V_top.round(2)}\")\n",
    "print(f\"Alt subspace - Initial U scales: {init_scales_U_alt.round(2)}\")\n",
    "print(f\"Alt subspace - Initial V scales: {init_scales_V_alt.round(2)}\")\n",
    "print()\n",
    "print(\"Key insight: ALS should adjust these random scalings to the optimal target scales!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run: Execute ALS Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RUNNING ALS ===\n",
      "Top subspace:\n",
      "  Converged after 12 iterations (rel_change: 3.35e-11)\n",
      "\n",
      "Alt subspace:\n",
      "  Converged after 9 iterations (rel_change: 3.29e-11)\n",
      "\n",
      "Final objectives:\n",
      "  Top subspace: 38.500000\n",
      "  Alt subspace: 70.500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d2/m1r5k9xs77n9kj281b15qkgw0000gn/T/ipykernel_8777/3752252611.py:19: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rel_change = abs(obj_prev - obj) / max(1.0, obj_prev)\n"
     ]
    }
   ],
   "source": [
    "def als_algorithm(Y, U0, V0, lam, max_iterations=100, tolerance=1e-10, verbose=True):\n",
    "    \"\"\"Run ALS algorithm with convergence tracking\"\"\"\n",
    "    U, V = U0.copy(), V0.copy()\n",
    "    obj_prev = np.inf\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        # ALS updates\n",
    "        VtV_reg = V.T @ V + lam * np.eye(V.shape[1])\n",
    "        U = Y @ V @ npl.inv(VtV_reg)\n",
    "        \n",
    "        UtU_reg = U.T @ U + lam * np.eye(U.shape[1])\n",
    "        V = Y.T @ U @ npl.inv(UtU_reg)\n",
    "        \n",
    "        # Compute objective\n",
    "        residual = Y - U @ V.T\n",
    "        obj = 0.5 * np.sum(residual**2) + 0.5 * lam * (np.sum(U**2) + np.sum(V**2))\n",
    "        \n",
    "        # Check convergence\n",
    "        rel_change = abs(obj_prev - obj) / max(1.0, obj_prev)\n",
    "        if rel_change < tolerance:\n",
    "            if verbose:\n",
    "                print(f\"  Converged after {iteration + 1} iterations (rel_change: {rel_change:.2e})\")\n",
    "            break\n",
    "        \n",
    "        obj_prev = obj\n",
    "    \n",
    "    return U, V, obj, iteration + 1\n",
    "\n",
    "print(\"=== RUNNING ALS ===\")\n",
    "print(\"Top subspace:\")\n",
    "U_result_top, V_result_top, obj_top, iters_top = als_algorithm(Y, U0_top, V0_top, lambda_reg)\n",
    "\n",
    "print(\"\\nAlt subspace:\")\n",
    "U_result_alt, V_result_alt, obj_alt, iters_alt = als_algorithm(Y, U0_alt, V0_alt, lambda_reg)\n",
    "\n",
    "print(f\"\\nFinal objectives:\")\n",
    "print(f\"  Top subspace: {obj_top:.6f}\")\n",
    "print(f\"  Alt subspace: {obj_alt:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Validate: Check Convergence Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VALIDATION RESULTS ===\n",
      "\n",
      "Test 1: Top subspace → Global minimum\n",
      "  Status: PASS ✓\n",
      "  Reconstruction error: 8.76e-06\n",
      "  Gram matrix errors: U=4.38e-05, V=2.63e-05\n",
      "\n",
      "Test 2: Alt subspace → Saddle point\n",
      "  Status: PASS ✓\n",
      "  Reconstruction error: 6.62e-06\n",
      "  Gram matrix errors: U=2.65e-05, V=1.32e-05\n",
      "\n",
      "Diagnostic: Alt → Top (should FAIL)\n",
      "  Status: FAIL ✗\n",
      "  Reconstruction error: 8.00e+00\n",
      "  Gram matrix errors: U=4.90e+00, V=4.90e+00\n"
     ]
    }
   ],
   "source": [
    "def validate_convergence(U_result, V_result, U_target, V_target, test_name, \n",
    "                        tol_reconstruction=1e-4):\n",
    "    \"\"\"Comprehensive validation of ALS convergence\"\"\"\n",
    "    \n",
    "    # 1. Reconstruction error (should be ~0 if found correct solution)\n",
    "    reconstruction_result = U_result @ V_result.T\n",
    "    reconstruction_target = U_target @ V_target.T\n",
    "    reconstruction_error = np.linalg.norm(reconstruction_result - reconstruction_target, 'fro')\n",
    "    \n",
    "    # 2. Scaling consistency via Gram matrices\n",
    "    gram_U_error = np.linalg.norm(U_result.T @ U_result - U_target.T @ U_target, 'fro')\n",
    "    gram_V_error = np.linalg.norm(V_result.T @ V_result - V_target.T @ V_target, 'fro')\n",
    "    \n",
    "    # Overall pass/fail\n",
    "    reconstruction_ok = reconstruction_error <= tol_reconstruction\n",
    "    overall_pass = reconstruction_ok\n",
    "    \n",
    "    status = \"PASS ✓\" if overall_pass else \"FAIL ✗\"\n",
    "    \n",
    "    print(f\"\\n{test_name}\")\n",
    "    print(f\"  Status: {status}\")\n",
    "    print(f\"  Reconstruction error: {reconstruction_error:.2e}\")\n",
    "    print(f\"  Gram matrix errors: U={gram_U_error:.2e}, V={gram_V_error:.2e}\")\n",
    "    \n",
    "    return {\n",
    "        'status': status,\n",
    "        'overall_pass': overall_pass,\n",
    "        'reconstruction_error': reconstruction_error,\n",
    "        'gram_U_error': gram_U_error,\n",
    "        'gram_V_error': gram_V_error\n",
    "    }\n",
    "\n",
    "print(\"=== VALIDATION RESULTS ===\")\n",
    "\n",
    "# Test 1: Top subspace should converge to global minimum\n",
    "result_top = validate_convergence(U_result_top, V_result_top, U_target_top, V_target_top, \n",
    "                                 \"Test 1: Top subspace → Global minimum\")\n",
    "\n",
    "# Test 2: Alt subspace should converge to saddle point\n",
    "result_alt = validate_convergence(U_result_alt, V_result_alt, U_target_alt, V_target_alt,\n",
    "                                 \"Test 2: Alt subspace → Saddle point\")\n",
    "\n",
    "# Diagnostic: Check if alt escaped to top solution (should be FAIL)\n",
    "result_escape = validate_convergence(U_result_alt, V_result_alt, U_target_top, V_target_top,\n",
    "                                   \"Diagnostic: Alt → Top (should FAIL)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary: Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EXPERIMENT SUMMARY\n",
      "==================================================\n",
      "\n",
      "Matrix: 10×8, Rank: 4, Regularization: λ=2\n",
      "Singular values: [10, 8, 4, 1]\n",
      "Latent rank: R=3\n",
      "\n",
      "Subspace Selection:\n",
      "  Top indices [0, 1, 2]: σ = [10.  8.  4.] → target scales = [2.83 2.45 1.41]\n",
      "  Alt indices [1, 2, 3]: σ = [8. 4. 1.] → target scales = [2.45 1.41 0.  ]\n",
      "\n",
      "Theoretical Prediction:\n",
      "  ALS should stay within initialized subspace\n",
      "  ALS should find MAP scaling via soft-thresholding formula\n",
      "\n",
      "Experimental Results:\n",
      "  Test 1 (Top → Global): PASS ✓\n",
      "  Test 2 (Alt → Saddle): PASS ✓\n",
      "  Diagnostic (Alt → Top): FAIL ✗ (expected to fail)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EXPERIMENT SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\nMatrix: {m}×{n}, Rank: {true_rank}, Regularization: λ={lambda_reg}\")\n",
    "print(f\"Singular values: {singular_values}\")\n",
    "print(f\"Latent rank: R={R}\")\n",
    "\n",
    "print(f\"\\nSubspace Selection:\")\n",
    "print(f\"  Top indices {top_indices}: σ = {sigma_top.round(1)} → target scales = {scales_top.round(2)}\")\n",
    "print(f\"  Alt indices {alt_indices}: σ = {sigma_alt.round(1)} → target scales = {scales_alt.round(2)}\")\n",
    "\n",
    "print(f\"\\nTheoretical Prediction:\")\n",
    "print(f\"  ALS should stay within initialized subspace\")\n",
    "print(f\"  ALS should find MAP scaling via soft-thresholding formula\")\n",
    "\n",
    "print(f\"\\nExperimental Results:\")\n",
    "print(f\"  Test 1 (Top → Global): {result_top['status']}\")\n",
    "print(f\"  Test 2 (Alt → Saddle): {result_alt['status']}\")\n",
    "print(f\"  Diagnostic (Alt → Top): {result_escape['status']} (expected to fail)\")\n",
    "\n",
    "both_pass = result_top['overall_pass'] and result_alt['overall_pass']\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Part 2] Starting incomplete-data soft-impute section.\n",
      "[Part 2] Using existing Y with shape=(10, 8), target rank R=3.\n",
      "[Part 2] Isotropic prior: lam = 2\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Part 2 — Incomplete data\n",
    "# Soft-Impute (MM) section\n",
    "# Assumptions carried from Part 1:\n",
    "#   - Y: (n x p) data matrix (fully observed)\n",
    "#   - R: target rank\n",
    "#   - Either 'lam' (isotropic scalar) OR 'Lambda' (R x R diagonal) is defined (NOT both).\n",
    "# =========================\n",
    "import numpy as np\n",
    "import numpy.linalg as npl\n",
    "\n",
    "print(\"[Part 2] Starting incomplete-data soft-impute section.\")\n",
    "print(f\"[Part 2] Using existing Y with shape={Y.shape}, target rank R={R}.\")\n",
    "lam = lambda_reg\n",
    "\n",
    "# Sanity: exactly one of lam or Lambda should be provided.\n",
    "lam_defined = 'lam' in globals() and lam is not None\n",
    "Lambda_defined = 'Lambda' in globals() and Lambda is not None\n",
    "\n",
    "if lam_defined and not Lambda_defined:\n",
    "    print(f\"[Part 2] Isotropic prior: lam = {lam:.6g}\")\n",
    "elif Lambda_defined and not lam_defined:\n",
    "    print(f\"[Part 2] Diagonal prior: diag(Lambda) = {np.diag(Lambda)}\")\n",
    "else:\n",
    "    raise ValueError(\"[Part 2] Please define exactly one: either 'lam' (scalar) OR 'Lambda' (diagonal R x R).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Part 2] Defined mask utilities and masked MAP loss (lam OR Lambda).\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 1: Mask utilities and masked MAP loss (supports lam OR diagonal Lambda) ---\n",
    "\n",
    "def make_mask(Y, pi=0.20, seed=0):\n",
    "    \"\"\"Return a binary mask M with P(M_ij = 1) = 1 - pi (observed).\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    M = (rng.random(size=Y.shape) > pi).astype(float)\n",
    "    return M\n",
    "\n",
    "def masked_map_loss(Y, M, U, V, lam=None, Lambda=None):\n",
    "    \"\"\"\n",
    "    Masked loss:\n",
    "      0.5 * || M ⊙ (Y - U V^T) ||_F^2 + 0.5 * [ lam*(||U||_F^2 + ||V||_F^2) ]  (if lam)\n",
    "      0.5 * || M ⊙ (Y - U V^T) ||_F^2 + 0.5 * [ tr(U^T Λ U) + tr(V^T Λ V) ]      (if Lambda)\n",
    "    Exactly one of lam or Lambda must be provided.\n",
    "    \"\"\"\n",
    "    Rmask = M * (Y - U @ V.T)\n",
    "    data_term = 0.5 * np.sum(Rmask * Rmask)\n",
    "\n",
    "    if (lam is None) == (Lambda is None):\n",
    "        raise ValueError(\"[masked_map_loss] Provide exactly one of lam or Lambda.\")\n",
    "\n",
    "    if Lambda is not None:\n",
    "        reg = 0.5 * (np.trace(U.T @ (Lambda @ U)) + np.trace(V.T @ (Lambda @ V)))\n",
    "    else:\n",
    "        reg = 0.5 * lam * (np.sum(U*U) + np.sum(V*V))\n",
    "\n",
    "    return data_term + reg\n",
    "\n",
    "print(\"[Part 2] Defined mask utilities and masked MAP loss (lam OR Lambda).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Part 2] Defined soft-thresholded SVD helper (lam OR Lambda).\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 2: Soft-thresholded SVD helper (supports lam OR diagonal Lambda) ---\n",
    "\n",
    "def soft_threshold_svd(Y_imp, R, lam=None, Lambda=None):\n",
    "    \"\"\"\n",
    "    SVD of imputed matrix, then soft-threshold singular values:\n",
    "      isotropic:       a_r = sqrt( max(s_r - lam, 0) )\n",
    "      diagonal Lambda: a_r = sqrt( max(s_r - lambda_r, 0) ), lambda_r = diag(Lambda)[r]\n",
    "    Returns U = F_R diag(a), V = G_R diag(a), and (F_R, G_R, s_R, a).\n",
    "    \"\"\"\n",
    "    if (lam is None) == (Lambda is None):\n",
    "        raise ValueError(\"[soft_threshold_svd] Provide exactly one of lam or Lambda.\")\n",
    "\n",
    "    F_imp, s_imp, Gt_imp = npl.svd(Y_imp, full_matrices=False)\n",
    "    G_imp = Gt_imp.T\n",
    "\n",
    "    F_R = F_imp[:, :R]\n",
    "    G_R = G_imp[:, :R]\n",
    "    s_R = s_imp[:R]\n",
    "\n",
    "    if Lambda is not None:\n",
    "        lam_vec = np.diag(Lambda)\n",
    "        if lam_vec.shape[0] != R:\n",
    "            raise ValueError(\"[soft_threshold_svd] diag(Lambda) length must equal R.\")\n",
    "        a = np.sqrt(np.maximum(s_R - lam_vec, 0.0))\n",
    "    else:\n",
    "        a = np.sqrt(np.maximum(s_R - lam, 0.0))\n",
    "\n",
    "    U = F_R @ np.diag(a)\n",
    "    V = G_R @ np.diag(a)\n",
    "    return U, V, F_R, G_R, s_R, a\n",
    "\n",
    "print(\"[Part 2] Defined soft-thresholded SVD helper (lam OR Lambda).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Part 2] Defined Soft-Impute loop (lam OR Lambda).\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 3: Soft-Impute loop (MM), with prints (supports lam OR Lambda) ---\n",
    "\n",
    "def soft_impute(Y, R, M, lam=None, Lambda=None, \n",
    "                init=\"from_full_soft_svd\", U0=None, V0=None, \n",
    "                maxit=200, tol=1e-8, seed=0, track_loss=True, verbose=True):\n",
    "    \"\"\"\n",
    "    Soft-Impute (impute + SVD + soft-threshold) for masked data.\n",
    "    init:\n",
    "      - \"from_full_soft_svd\": start from soft-thresholded SVD of full Y (Part 1)\n",
    "      - \"given\": use provided (U0, V0) (e.g., alternative subspace start)\n",
    "    Supports isotropic 'lam' OR diagonal 'Lambda' (not both).\n",
    "    \"\"\"\n",
    "    if (lam is None) == (Lambda is None):\n",
    "        raise ValueError(\"[soft_impute] Provide exactly one of lam or Lambda.\")\n",
    "\n",
    "    n, p = Y.shape\n",
    "    if verbose:\n",
    "        pi = 1.0 - M.mean()\n",
    "        hdr = f\"[Soft-Impute] n={n}, p={p}, R={R}, missing pi={pi:.2f}, tol={tol}, maxit={maxit}\"\n",
    "        print(hdr)\n",
    "        if Lambda is not None:\n",
    "            print(f\"[Soft-Impute] Using diagonal Lambda: {np.diag(Lambda)}\")\n",
    "        else:\n",
    "            print(f\"[Soft-Impute] Using isotropic lam: {lam:.6g}\")\n",
    "        print(f\"[Soft-Impute] init mode: {init}\")\n",
    "\n",
    "    # initialization\n",
    "    if init == \"from_full_soft_svd\":\n",
    "        U, V, _, _, _, a0 = soft_threshold_svd(Y, R, lam=lam, Lambda=Lambda)\n",
    "        if verbose:\n",
    "            print(f\"[Soft-Impute] init from full-Y soft-SVD: initial scales a0 = {a0}\")\n",
    "    elif init == \"given\":\n",
    "        assert (U0 is not None) and (V0 is not None), \"[Soft-Impute] 'given' init requires U0 and V0.\"\n",
    "        U, V = U0.copy(), V0.copy()\n",
    "        if verbose:\n",
    "            print(\"[Soft-Impute] init from given U0, V0.\")\n",
    "    else:\n",
    "        raise ValueError(\"[soft_impute] Unknown init option.\")\n",
    "\n",
    "    history = []\n",
    "    Y_imp_prev = None\n",
    "\n",
    "    for it in range(maxit):\n",
    "        # a) Impute: observed entries = Y; missing = U V^T\n",
    "        Y_imp = M * Y + (1.0 - M) * (U @ V.T)\n",
    "\n",
    "        # Convergence on imputed matrix:\n",
    "        if Y_imp_prev is not None:\n",
    "            rel = npl.norm(Y_imp - Y_imp_prev, 'fro') / max(1.0, npl.norm(Y_imp_prev, 'fro'))\n",
    "            if verbose and (it % 10 == 0):\n",
    "                print(f\"[Soft-Impute] iter {it:3d} | rel change (imputed) = {rel:.3e}\")\n",
    "            if rel < tol:\n",
    "                if verbose:\n",
    "                    print(f\"[Soft-Impute] Converged at iter {it} with rel change {rel:.3e}.\")\n",
    "                break\n",
    "        Y_imp_prev = Y_imp\n",
    "\n",
    "        # b) SVD + soft-threshold update\n",
    "        U, V, F_R, G_R, s_R, a = soft_threshold_svd(Y_imp, R, lam=lam, Lambda=Lambda)\n",
    "\n",
    "        if track_loss:\n",
    "            curr_loss = masked_map_loss(Y, M, U, V, lam=lam, Lambda=Lambda)\n",
    "            history.append(curr_loss)\n",
    "            if verbose and (it % 10 == 0):\n",
    "                print(f\"[Soft-Impute] iter {it:3d} | masked MAP loss = {curr_loss:.6e}\")\n",
    "\n",
    "    out = {\n",
    "        \"U\": U, \"V\": V,\n",
    "        \"F_R\": F_R, \"G_R\": G_R, \"s_R\": s_R, \"a\": a,\n",
    "        \"Y_imp\": Y_imp, \"loss_hist\": history\n",
    "    }\n",
    "    if verbose:\n",
    "        print(\"[Soft-Impute] Done.\")\n",
    "        print(f\"[Soft-Impute] final scales a = {a}\")\n",
    "    return out\n",
    "\n",
    "print(\"[Part 2] Defined Soft-Impute loop (lam OR Lambda).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Part 2] Mask created with missing probability pi=0.2, observed fraction=0.81.\n",
      "[Soft-Impute] n=10, p=8, R=3, missing pi=0.19, tol=1e-10, maxit=200\n",
      "[Soft-Impute] Using isotropic lam: 2\n",
      "[Soft-Impute] init mode: from_full_soft_svd\n",
      "[Soft-Impute] init from full-Y soft-SVD: initial scales a0 = [2.82842712 2.44948974 1.41421356]\n",
      "[Soft-Impute] iter   0 | masked MAP loss = 3.635243e+01\n",
      "[Soft-Impute] iter  10 | rel change (imputed) = 4.339e-04\n",
      "[Soft-Impute] iter  10 | masked MAP loss = 3.592864e+01\n",
      "[Soft-Impute] iter  20 | rel change (imputed) = 8.985e-06\n",
      "[Soft-Impute] iter  20 | masked MAP loss = 3.592863e+01\n",
      "[Soft-Impute] iter  30 | rel change (imputed) = 2.663e-07\n",
      "[Soft-Impute] iter  30 | masked MAP loss = 3.592863e+01\n",
      "[Soft-Impute] iter  40 | rel change (imputed) = 8.284e-09\n",
      "[Soft-Impute] iter  40 | masked MAP loss = 3.592863e+01\n",
      "[Soft-Impute] iter  50 | rel change (imputed) = 2.589e-10\n",
      "[Soft-Impute] iter  50 | masked MAP loss = 3.592863e+01\n",
      "[Soft-Impute] Converged at iter 53 with rel change 9.153e-11.\n",
      "[Soft-Impute] Done.\n",
      "[Soft-Impute] final scales a = [2.7346445  2.24691007 1.2343751 ]\n",
      "[Part 2] Soft-Impute completed.\n",
      "[Part 2] Final scales a_tilde = [2.7346445  2.24691007 1.2343751 ]\n",
      "[Part 2] Shapes: U~ = (10, 3), V~ = (8, 3), Y_imp = (10, 8)\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 4: Create mask and run Soft-Impute (start from full-Y soft-thresholded SVD) ---\n",
    "\n",
    "pi = 0.20\n",
    "seed = 42\n",
    "M = make_mask(Y, pi=pi, seed=seed)\n",
    "print(f\"[Part 2] Mask created with missing probability pi={pi}, observed fraction={M.mean():.2f}.\")\n",
    "\n",
    "res_si = soft_impute(\n",
    "    Y=Y, R=R, M=M,\n",
    "    lam=lam if lam_defined else None,\n",
    "    Lambda=Lambda if Lambda_defined else None,\n",
    "    init=\"from_full_soft_svd\",\n",
    "    maxit=200, tol=1e-10, seed=seed,\n",
    "    track_loss=True, verbose=True\n",
    ")\n",
    "\n",
    "U_tilde, V_tilde = res_si[\"U\"], res_si[\"V\"]\n",
    "F_tilde, G_tilde, s_tilde, a_tilde = res_si[\"F_R\"], res_si[\"G_R\"], res_si[\"s_R\"], res_si[\"a\"]\n",
    "Y_imp_final = res_si[\"Y_imp\"]\n",
    "\n",
    "print(\"[Part 2] Soft-Impute completed.\")\n",
    "print(f\"[Part 2] Final scales a_tilde = {a_tilde}\")\n",
    "print(f\"[Part 2] Shapes: U~ = {U_tilde.shape}, V~ = {V_tilde.shape}, Y_imp = {Y_imp_final.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Part 2] Plotted masked MAP loss.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 5: (Optional) Plot masked loss monotone decrease ---\n",
    "\n",
    "if res_si[\"loss_hist\"]:\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure()\n",
    "    plt.plot(res_si[\"loss_hist\"], marker='o')\n",
    "    plt.title(\"Masked MAP loss (Soft-Impute)\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    print(\"[Part 2] Plotted masked MAP loss.\")\n",
    "else:\n",
    "    print(\"[Part 2] No loss history was recorded (track_loss=False).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Part 2] Restart test: soft-impute from the converged (U~, V~).\n",
      "[Soft-Impute] n=10, p=8, R=3, missing pi=0.19, tol=1e-12, maxit=3\n",
      "[Soft-Impute] Using isotropic lam: 2\n",
      "[Soft-Impute] init mode: given\n",
      "[Soft-Impute] init from given U0, V0.\n",
      "[Soft-Impute] Done.\n",
      "[Soft-Impute] final scales a = [2.7346445  2.24691007 1.2343751 ]\n",
      "[Part 2] Restart deltas (should be ~0): ||ΔU||_F=1.288e-09, ||ΔV||_F=1.059e-09, ||ΔY_imp||_F=1.378e-09\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 6: Stationarity / restart test (crucial) ---\n",
    "\n",
    "print(\"[Part 2] Restart test: soft-impute from the converged (U~, V~).\")\n",
    "res_restart = soft_impute(\n",
    "    Y=Y, R=R, M=M,\n",
    "    lam=lam if lam_defined else None,\n",
    "    Lambda=Lambda if Lambda_defined else None,\n",
    "    init=\"given\", U0=U_tilde, V0=V_tilde,\n",
    "    maxit=3, tol=1e-12, seed=seed,\n",
    "    track_loss=False, verbose=True\n",
    ")\n",
    "\n",
    "U_restart, V_restart = res_restart[\"U\"], res_restart[\"V\"]\n",
    "Y_imp_restart = res_restart[\"Y_imp\"]\n",
    "\n",
    "delta_U = npl.norm(U_restart - U_tilde, 'fro')\n",
    "delta_V = npl.norm(V_restart - V_tilde, 'fro')\n",
    "delta_Yimp = npl.norm(Y_imp_restart - Y_imp_final, 'fro')\n",
    "\n",
    "print(f\"[Part 2] Restart deltas (should be ~0): ||ΔU||_F={delta_U:.3e}, ||ΔV||_F={delta_V:.3e}, ||ΔY_imp||_F={delta_Yimp:.3e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Part 2] Found alternative soft-thresholded start (U_target_alt, V_target_alt). Running soft-impute...\n",
      "[Soft-Impute] n=10, p=8, R=3, missing pi=0.19, tol=1e-10, maxit=200\n",
      "[Soft-Impute] Using isotropic lam: 2\n",
      "[Soft-Impute] init mode: given\n",
      "[Soft-Impute] init from given U0, V0.\n",
      "[Soft-Impute] iter   0 | masked MAP loss = 3.676340e+01\n",
      "[Soft-Impute] iter  10 | rel change (imputed) = 9.592e-04\n",
      "[Soft-Impute] iter  10 | masked MAP loss = 3.592871e+01\n",
      "[Soft-Impute] iter  20 | rel change (imputed) = 2.835e-05\n",
      "[Soft-Impute] iter  20 | masked MAP loss = 3.592863e+01\n",
      "[Soft-Impute] iter  30 | rel change (imputed) = 8.840e-07\n",
      "[Soft-Impute] iter  30 | masked MAP loss = 3.592863e+01\n",
      "[Soft-Impute] iter  40 | rel change (imputed) = 2.763e-08\n",
      "[Soft-Impute] iter  40 | masked MAP loss = 3.592863e+01\n",
      "[Soft-Impute] iter  50 | rel change (imputed) = 8.637e-10\n",
      "[Soft-Impute] iter  50 | masked MAP loss = 3.592863e+01\n",
      "[Soft-Impute] Converged at iter 57 with rel change 7.637e-11.\n",
      "[Soft-Impute] Done.\n",
      "[Soft-Impute] final scales a = [2.7346445  2.24691007 1.2343751 ]\n",
      "[Part 2] Subspace distance (alt-run U vs main-run U~): 2.980e-08\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 7: (Optional) Alternative initialization from a non-top subspace ---\n",
    "\n",
    "# If in Part 1 you formed (U_star_alt, V_star_alt) by soft-thresholding an alternative set of singular vectors,\n",
    "# you can test sensitivity by starting from that pair:\n",
    "\n",
    "try:\n",
    "    U_target_alt, V_target_alt  # check if they exist\n",
    "    print(\"[Part 2] Found alternative soft-thresholded start (U_target_alt, V_target_alt). Running soft-impute...\")\n",
    "    res_si_alt = soft_impute(\n",
    "        Y=Y, R=R, M=M,\n",
    "        lam=lam if lam_defined else None,\n",
    "        Lambda=Lambda if Lambda_defined else None,\n",
    "        init=\"given\", U0=U_target_alt, V0=V_target_alt,\n",
    "        maxit=200, tol=1e-10, seed=seed,\n",
    "        track_loss=True, verbose=True\n",
    "    )\n",
    "\n",
    "    def subspace_distance(A, B):\n",
    "        QA, _ = npl.qr(A); QB, _ = npl.qr(B)\n",
    "        svals = np.clip(npl.svd(QA.T @ QB, compute_uv=False), 0.0, 1.0)\n",
    "        return np.sin(np.arccos(svals).max()) if len(svals) else 0.0\n",
    "\n",
    "    dist_alt_vs_main = subspace_distance(res_si_alt[\"U\"], U_tilde)\n",
    "    print(f\"[Part 2] Subspace distance (alt-run U vs main-run U~): {dist_alt_vs_main:.3e}\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"[Part 2] No (U_star_alt, V_star_alt) defined in Part 1; skipping alternative init test.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
