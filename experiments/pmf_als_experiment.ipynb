{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PMF–ALS Experiment: Testing Subspace Invariance Theory\n",
    "\n",
    "## Core Theoretical Claim\n",
    "\n",
    "**When ALS is initialized in the subspace spanned by specific singular vectors of Y, it will:**\n",
    "1. **Stay in that subspace** (subspace invariance)\n",
    "2. **Converge to the stationary point** obtained by soft-thresholding the corresponding singular values\n",
    "\n",
    "## Mathematical Setup\n",
    "\n",
    "- **MAP Objective:** $L(U,V) = \\frac{1}{2}\\|Y - UV^\\top\\|_F^2 + \\frac{\\lambda}{2}(\\|U\\|_F^2 + \\|V\\|_F^2)$\n",
    "- **Global Minimizer:** $U^* = F_R \\text{diag}\\big(\\sqrt{(\\sigma_i - \\lambda)_+}\\big)$, $V^* = G_R \\text{diag}\\big(\\sqrt{(\\sigma_i - \\lambda)_+}\\big)$\n",
    "- **Soft-thresholding:** $(x)_+ = \\max(x,0)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup: Parameters and Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPERIMENT SETUP ===\n",
      "Matrix size: 10 × 8\n",
      "Singular values: [10, 8, 4, 1]\n",
      "Regularization λ = 2\n",
      "Latent rank R = 3\n",
      "Top subspace indices: [0, 1, 2]\n",
      "Alt subspace indices: [1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as npl\n",
    "\n",
    "# Fixed seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# === EXPERIMENT PARAMETERS ===\n",
    "# Matrix dimensions (smaller for clarity)\n",
    "m, n = 10, 8\n",
    "true_rank = 4\n",
    "\n",
    "# Clean integer singular values (hardcoded for interpretability)\n",
    "# add some noise to singular values\n",
    "singular_values = [10, 8, 4, 1] \n",
    "\n",
    "# ALS parameters\n",
    "R = 3                  # Latent factorization rank\n",
    "lambda_reg = 2         # Regularization parameter\n",
    "\n",
    "# Subspace selection\n",
    "top_indices = [0, 1, 2]        # Top 3 singular vectors\n",
    "alt_indices = [1, 2, 3]        # Alternative 3 (overlapping set)\n",
    "\n",
    "print(\"=== EXPERIMENT SETUP ===\")\n",
    "print(f\"Matrix size: {m} × {n}\")\n",
    "print(f\"Singular values: {singular_values}\")\n",
    "print(f\"Regularization λ = {lambda_reg}\")\n",
    "print(f\"Latent rank R = {R}\")\n",
    "print(f\"Top subspace indices: {top_indices}\")\n",
    "print(f\"Alt subspace indices: {alt_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DATA GENERATION VERIFICATION ===\n",
      "Y shape: (10, 8)\n",
      "Recovered singular values: [10.  8.  4.  1.]\n",
      "Expected singular values:  [10, 8, 4, 1]\n",
      "Match: True\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic matrix with known structure\n",
    "# Y = U_true * S_true * V_true^T\n",
    "U_true, _ = np.linalg.qr(np.random.randn(m, true_rank))\n",
    "V_true, _ = np.linalg.qr(np.random.randn(n, true_rank))\n",
    "Y = U_true @ np.diag(singular_values) @ V_true.T\n",
    "\n",
    "# Compute SVD of Y (should recover our structure)\n",
    "U_svd, s_svd, Vt_svd = npl.svd(Y, full_matrices=False)\n",
    "V_svd = Vt_svd.T\n",
    "\n",
    "print(\"\\n=== DATA GENERATION VERIFICATION ===\")\n",
    "print(f\"Y shape: {Y.shape}\")\n",
    "print(f\"Recovered singular values: {s_svd[:4].round(6)}\")\n",
    "print(f\"Expected singular values:  {singular_values}\")\n",
    "print(f\"Match: {np.allclose(s_svd[:4], singular_values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Theory: Expected Solutions via Soft-Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SOFT-THRESHOLDING ANALYSIS ===\n",
      "Regularization λ = 2\n",
      "\n",
      "Top subspace (indices [0, 1, 2]):\n",
      "  Singular values: [10.  8.  4.]\n",
      "  After thresholding: [8. 6. 2.]\n",
      "  Target scales: [2.828 2.449 1.414]\n",
      "\n",
      "Alt subspace (indices [1, 2, 3]):\n",
      "  Singular values: [8. 4. 1.]\n",
      "  After thresholding: [6. 2. 0.]\n",
      "  Target scales: [2.449 1.414 0.   ]\n"
     ]
    }
   ],
   "source": [
    "def soft_threshold(sigma, lam):\n",
    "    \"\"\"Apply soft-thresholding: max(sigma - lambda, 0)\"\"\"\n",
    "    return np.maximum(sigma - lam, 0.0)\n",
    "\n",
    "def compute_map_solution(U_svd_subset, V_svd_subset, sigma_subset, lam):\n",
    "    \"\"\"Compute MAP solution U*, V* for given subspace\"\"\"\n",
    "    # Apply soft-thresholding to get target scalings\n",
    "    target_scales = np.sqrt(soft_threshold(sigma_subset, lam))\n",
    "    \n",
    "    # Form MAP solution matrices\n",
    "    U_target = U_svd_subset @ np.diag(target_scales)\n",
    "    V_target = V_svd_subset @ np.diag(target_scales)\n",
    "    \n",
    "    return U_target, V_target, target_scales\n",
    "\n",
    "# Extract subspace components\n",
    "U_svd_top = U_svd[:, top_indices]\n",
    "V_svd_top = V_svd[:, top_indices] \n",
    "sigma_top = s_svd[top_indices]\n",
    "\n",
    "U_svd_alt = U_svd[:, alt_indices]\n",
    "V_svd_alt = V_svd[:, alt_indices]\n",
    "sigma_alt = s_svd[alt_indices]\n",
    "\n",
    "# Compute theoretical MAP solutions\n",
    "U_target_top, V_target_top, scales_top = compute_map_solution(U_svd_top, V_svd_top, sigma_top, lambda_reg)\n",
    "U_target_alt, V_target_alt, scales_alt = compute_map_solution(U_svd_alt, V_svd_alt, sigma_alt, lambda_reg)\n",
    "\n",
    "print(\"=== SOFT-THRESHOLDING ANALYSIS ===\")\n",
    "print(f\"Regularization λ = {lambda_reg}\")\n",
    "print()\n",
    "print(f\"Top subspace (indices {top_indices}):\")\n",
    "print(f\"  Singular values: {sigma_top.round(2)}\")\n",
    "print(f\"  After thresholding: {soft_threshold(sigma_top, lambda_reg).round(2)}\")\n",
    "print(f\"  Target scales: {scales_top.round(3)}\")\n",
    "print()\n",
    "print(f\"Alt subspace (indices {alt_indices}):\")\n",
    "print(f\"  Singular values: {sigma_alt.round(2)}\")\n",
    "print(f\"  After thresholding: {soft_threshold(sigma_alt, lambda_reg).round(2)}\")\n",
    "print(f\"  Target scales: {scales_alt.round(3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize: Set ALS Starting Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INITIALIZATION ===\n",
      "Top subspace - Initial U scales: [1.66 1.24 1.28]\n",
      "Top subspace - Initial V scales: [1.14 0.54 0.66]\n",
      "Alt subspace - Initial U scales: [0.55 1.45 0.97]\n",
      "Alt subspace - Initial V scales: [1.26 1.86 0.87]\n",
      "\n",
      "Key insight: ALS should adjust these random scalings to the optimal target scales!\n"
     ]
    }
   ],
   "source": [
    "def initialize_in_subspace(U_svd_subset, V_svd_subset, scale_range=(0.5, 2.0)):\n",
    "    \"\"\"Initialize U0, V0 in given subspace with random scalings\"\"\"\n",
    "    R = U_svd_subset.shape[1]\n",
    "    \n",
    "    # Random scaling factors\n",
    "    scales_U = np.random.uniform(scale_range[0], scale_range[1], R)\n",
    "    scales_V = np.random.uniform(scale_range[0], scale_range[1], R)\n",
    "    \n",
    "    # Initialize in subspace with random scalings\n",
    "    U0 = U_svd_subset @ np.diag(scales_U)\n",
    "    V0 = V_svd_subset @ np.diag(scales_V)\n",
    "    \n",
    "    return U0, V0, scales_U, scales_V\n",
    "\n",
    "# Initialize ALS starting points in each subspace\n",
    "U0_top, V0_top, init_scales_U_top, init_scales_V_top = initialize_in_subspace(U_svd_top, V_svd_top)\n",
    "U0_alt, V0_alt, init_scales_U_alt, init_scales_V_alt = initialize_in_subspace(U_svd_alt, V_svd_alt)\n",
    "\n",
    "print(\"=== INITIALIZATION ===\")\n",
    "print(f\"Top subspace - Initial U scales: {init_scales_U_top.round(2)}\")\n",
    "print(f\"Top subspace - Initial V scales: {init_scales_V_top.round(2)}\")\n",
    "print(f\"Alt subspace - Initial U scales: {init_scales_U_alt.round(2)}\")\n",
    "print(f\"Alt subspace - Initial V scales: {init_scales_V_alt.round(2)}\")\n",
    "print()\n",
    "print(\"Key insight: ALS should adjust these random scalings to the optimal target scales!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run: Execute ALS Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RUNNING ALS ===\n",
      "Top subspace:\n",
      "  Converged after 12 iterations (rel_change: 3.35e-11)\n",
      "\n",
      "Alt subspace:\n",
      "  Converged after 9 iterations (rel_change: 3.29e-11)\n",
      "\n",
      "Final objectives:\n",
      "  Top subspace: 38.500000\n",
      "  Alt subspace: 70.500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d2/m1r5k9xs77n9kj281b15qkgw0000gn/T/ipykernel_11689/3752252611.py:19: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rel_change = abs(obj_prev - obj) / max(1.0, obj_prev)\n"
     ]
    }
   ],
   "source": [
    "def als_algorithm(Y, U0, V0, lam, max_iterations=100, tolerance=1e-10, verbose=True):\n",
    "    \"\"\"Run ALS algorithm with convergence tracking\"\"\"\n",
    "    U, V = U0.copy(), V0.copy()\n",
    "    obj_prev = np.inf\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        # ALS updates\n",
    "        VtV_reg = V.T @ V + lam * np.eye(V.shape[1])\n",
    "        U = Y @ V @ npl.inv(VtV_reg)\n",
    "        \n",
    "        UtU_reg = U.T @ U + lam * np.eye(U.shape[1])\n",
    "        V = Y.T @ U @ npl.inv(UtU_reg)\n",
    "        \n",
    "        # Compute objective\n",
    "        residual = Y - U @ V.T\n",
    "        obj = 0.5 * np.sum(residual**2) + 0.5 * lam * (np.sum(U**2) + np.sum(V**2))\n",
    "        \n",
    "        # Check convergence\n",
    "        rel_change = abs(obj_prev - obj) / max(1.0, obj_prev)\n",
    "        if rel_change < tolerance:\n",
    "            if verbose:\n",
    "                print(f\"  Converged after {iteration + 1} iterations (rel_change: {rel_change:.2e})\")\n",
    "            break\n",
    "        \n",
    "        obj_prev = obj\n",
    "    \n",
    "    return U, V, obj, iteration + 1\n",
    "\n",
    "print(\"=== RUNNING ALS ===\")\n",
    "print(\"Top subspace:\")\n",
    "U_result_top, V_result_top, obj_top, iters_top = als_algorithm(Y, U0_top, V0_top, lambda_reg)\n",
    "\n",
    "print(\"\\nAlt subspace:\")\n",
    "U_result_alt, V_result_alt, obj_alt, iters_alt = als_algorithm(Y, U0_alt, V0_alt, lambda_reg)\n",
    "\n",
    "print(f\"\\nFinal objectives:\")\n",
    "print(f\"  Top subspace: {obj_top:.6f}\")\n",
    "print(f\"  Alt subspace: {obj_alt:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Validate: Check Convergence Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VALIDATION RESULTS ===\n",
      "\n",
      "Test 1: Top subspace → Global minimum\n",
      "  Status: PASS ✓\n",
      "  Reconstruction error: 8.76e-06\n",
      "  Gram matrix errors: U=4.38e-05, V=2.63e-05\n",
      "\n",
      "Test 2: Alt subspace → Saddle point\n",
      "  Status: PASS ✓\n",
      "  Reconstruction error: 6.62e-06\n",
      "  Gram matrix errors: U=2.65e-05, V=1.32e-05\n",
      "\n",
      "Diagnostic: Alt → Top (should FAIL)\n",
      "  Status: FAIL ✗\n",
      "  Reconstruction error: 8.00e+00\n",
      "  Gram matrix errors: U=4.90e+00, V=4.90e+00\n"
     ]
    }
   ],
   "source": [
    "def validate_convergence(U_result, V_result, U_target, V_target, test_name, \n",
    "                        tol_subspace=1e-4, tol_reconstruction=1e-4):\n",
    "    \"\"\"Comprehensive validation of ALS convergence\"\"\"\n",
    "    \n",
    "    # 1. Reconstruction error (should be ~0 if found correct solution)\n",
    "    reconstruction_result = U_result @ V_result.T\n",
    "    reconstruction_target = U_target @ V_target.T\n",
    "    reconstruction_error = np.linalg.norm(reconstruction_result - reconstruction_target, 'fro')\n",
    "    \n",
    "    # 2. Scaling consistency via Gram matrices\n",
    "    gram_U_error = np.linalg.norm(U_result.T @ U_result - U_target.T @ U_target, 'fro')\n",
    "    gram_V_error = np.linalg.norm(V_result.T @ V_result - V_target.T @ V_target, 'fro')\n",
    "    \n",
    "    # Overall pass/fail\n",
    "    reconstruction_ok = reconstruction_error <= tol_reconstruction\n",
    "    overall_pass = reconstruction_ok\n",
    "    \n",
    "    status = \"PASS ✓\" if overall_pass else \"FAIL ✗\"\n",
    "    \n",
    "    print(f\"\\n{test_name}\")\n",
    "    print(f\"  Status: {status}\")\n",
    "    print(f\"  Reconstruction error: {reconstruction_error:.2e}\")\n",
    "    print(f\"  Gram matrix errors: U={gram_U_error:.2e}, V={gram_V_error:.2e}\")\n",
    "    \n",
    "    return {\n",
    "        'status': status,\n",
    "        'overall_pass': overall_pass,\n",
    "        'reconstruction_error': reconstruction_error,\n",
    "        'gram_U_error': gram_U_error,\n",
    "        'gram_V_error': gram_V_error\n",
    "    }\n",
    "\n",
    "print(\"=== VALIDATION RESULTS ===\")\n",
    "\n",
    "# Test 1: Top subspace should converge to global minimum\n",
    "result_top = validate_convergence(U_result_top, V_result_top, U_target_top, V_target_top, \n",
    "                                 \"Test 1: Top subspace → Global minimum\")\n",
    "\n",
    "# Test 2: Alt subspace should converge to saddle point\n",
    "result_alt = validate_convergence(U_result_alt, V_result_alt, U_target_alt, V_target_alt,\n",
    "                                 \"Test 2: Alt subspace → Saddle point\")\n",
    "\n",
    "# Diagnostic: Check if alt escaped to top solution (should be FAIL)\n",
    "result_escape = validate_convergence(U_result_alt, V_result_alt, U_target_top, V_target_top,\n",
    "                                   \"Diagnostic: Alt → Top (should FAIL)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary: Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EXPERIMENT SUMMARY\n",
      "==================================================\n",
      "\n",
      "Matrix: 10×8, Rank: 4, Regularization: λ=2\n",
      "Singular values: [10, 8, 4, 1]\n",
      "Latent rank: R=3\n",
      "\n",
      "Subspace Selection:\n",
      "  Top indices [0, 1, 2]: σ = [10.  8.  4.] → target scales = [2.83 2.45 1.41]\n",
      "  Alt indices [1, 2, 3]: σ = [8. 4. 1.] → target scales = [2.45 1.41 0.  ]\n",
      "\n",
      "Theoretical Prediction:\n",
      "  ALS should stay within initialized subspace\n",
      "  ALS should find MAP scaling via soft-thresholding formula\n",
      "\n",
      "Experimental Results:\n",
      "  Test 1 (Top → Global): PASS ✓\n",
      "  Test 2 (Alt → Saddle): PASS ✓\n",
      "  Diagnostic (Alt → Top): FAIL ✗ (expected to fail)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EXPERIMENT SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\nMatrix: {m}×{n}, Rank: {true_rank}, Regularization: λ={lambda_reg}\")\n",
    "print(f\"Singular values: {singular_values}\")\n",
    "print(f\"Latent rank: R={R}\")\n",
    "\n",
    "print(f\"\\nSubspace Selection:\")\n",
    "print(f\"  Top indices {top_indices}: σ = {sigma_top.round(1)} → target scales = {scales_top.round(2)}\")\n",
    "print(f\"  Alt indices {alt_indices}: σ = {sigma_alt.round(1)} → target scales = {scales_alt.round(2)}\")\n",
    "\n",
    "print(f\"\\nTheoretical Prediction:\")\n",
    "print(f\"  ALS should stay within initialized subspace\")\n",
    "print(f\"  ALS should find MAP scaling via soft-thresholding formula\")\n",
    "\n",
    "print(f\"\\nExperimental Results:\")\n",
    "print(f\"  Test 1 (Top → Global): {result_top['status']}\")\n",
    "print(f\"  Test 2 (Alt → Saddle): {result_alt['status']}\")\n",
    "print(f\"  Diagnostic (Alt → Top): {result_escape['status']} (expected to fail)\")\n",
    "\n",
    "both_pass = result_top['overall_pass'] and result_alt['overall_pass']\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
